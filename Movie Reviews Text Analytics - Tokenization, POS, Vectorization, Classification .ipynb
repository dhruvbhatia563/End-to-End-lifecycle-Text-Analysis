{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6fba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d91ff6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>year</th>\n",
       "      <th>review_length</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound_scores</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>paulclaassen</td>\n",
       "      <td>https://www.imdb.com/review/rw8032959/?ref_=tt...</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Over-complicated, way too long, and not all th...</td>\n",
       "      <td>2022</td>\n",
       "      <td>58</td>\n",
       "      <td>{'neg': 0.247, 'neu': 0.753, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>neil</td>\n",
       "      <td>https://www.imdb.com/review/rw6050469/?ref_=tt...</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Far too clever for its own good</td>\n",
       "      <td>2020</td>\n",
       "      <td>31</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.459, 'pos': 0.541, 'comp...</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pedroborges</td>\n",
       "      <td>https://www.imdb.com/review/rw6217957/?ref_=tt...</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Tenet Review</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        author  \\\n",
       "0           0  paulclaassen   \n",
       "1           1          neil   \n",
       "2           2   pedroborges   \n",
       "\n",
       "                                                 url        date  rating  \\\n",
       "0  https://www.imdb.com/review/rw8032959/?ref_=tt...  2022-04-04     5.0   \n",
       "1  https://www.imdb.com/review/rw6050469/?ref_=tt...  2020-08-31     5.0   \n",
       "2  https://www.imdb.com/review/rw6217957/?ref_=tt...  2020-10-30     7.0   \n",
       "\n",
       "                                              review  year  review_length  \\\n",
       "0  Over-complicated, way too long, and not all th...  2022             58   \n",
       "1                    Far too clever for its own good  2020             31   \n",
       "2                                       Tenet Review  2020             12   \n",
       "\n",
       "                                              scores  compound_scores  \\\n",
       "0  {'neg': 0.247, 'neu': 0.753, 'pos': 0.0, 'comp...          -0.3875   \n",
       "1  {'neg': 0.0, 'neu': 0.459, 'pos': 0.541, 'comp...           0.7096   \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...           0.0000   \n",
       "\n",
       "     labels  \n",
       "0  negative  \n",
       "1  positive  \n",
       "2   neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tenet_movie_reviews_cleaned_dataset.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8416a6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'author', 'url', 'date', 'rating', 'review', 'year',\n",
       "       'review_length', 'scores', 'compound_scores', 'labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0159d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8548c6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>year</th>\n",
       "      <th>review_length</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound_scores</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paulclaassen</td>\n",
       "      <td>https://www.imdb.com/review/rw8032959/?ref_=tt...</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Over-complicated, way too long, and not all th...</td>\n",
       "      <td>2022</td>\n",
       "      <td>58</td>\n",
       "      <td>{'neg': 0.247, 'neu': 0.753, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neil</td>\n",
       "      <td>https://www.imdb.com/review/rw6050469/?ref_=tt...</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Far too clever for its own good</td>\n",
       "      <td>2020</td>\n",
       "      <td>31</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.459, 'pos': 0.541, 'comp...</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                                url  \\\n",
       "0  paulclaassen  https://www.imdb.com/review/rw8032959/?ref_=tt...   \n",
       "1          neil  https://www.imdb.com/review/rw6050469/?ref_=tt...   \n",
       "\n",
       "         date  rating                                             review  \\\n",
       "0  2022-04-04     5.0  Over-complicated, way too long, and not all th...   \n",
       "1  2020-08-31     5.0                    Far too clever for its own good   \n",
       "\n",
       "   year  review_length                                             scores  \\\n",
       "0  2022             58  {'neg': 0.247, 'neu': 0.753, 'pos': 0.0, 'comp...   \n",
       "1  2020             31  {'neg': 0.0, 'neu': 0.459, 'pos': 0.541, 'comp...   \n",
       "\n",
       "   compound_scores    labels  \n",
       "0          -0.3875  negative  \n",
       "1           0.7096  positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca75045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355d76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856164e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de619c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f3a9766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over-complicated, way too long, and not all that exciting.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fb581b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over-complicated, way too long, and not all that exciting.\n",
      "PUNCT\n",
      "--------------------\n",
      "PUNCT\n",
      "--------------------\n",
      "PUNCT\n",
      "--------------------\n",
      "PUNCT\n",
      "--------------------\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "print(doc.text)\n",
    "\n",
    "for word in doc:\n",
    "    if (word.pos_) == 'PUNCT':\n",
    "        count = count+1\n",
    "        print(word.pos_)\n",
    "        print('--------------------')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de64d220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5178 entries, 0 to 5177\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   author           5178 non-null   object \n",
      " 1   url              5178 non-null   object \n",
      " 2   date             5178 non-null   object \n",
      " 3   rating           5178 non-null   float64\n",
      " 4   review           5178 non-null   object \n",
      " 5   year             5178 non-null   int64  \n",
      " 6   review_length    5178 non-null   int64  \n",
      " 7   scores           5178 non-null   object \n",
      " 8   compound_scores  5178 non-null   float64\n",
      " 9   labels           5178 non-null   object \n",
      "dtypes: float64(2), int64(2), object(6)\n",
      "memory usage: 404.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4354ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5178 entries, 0 to 5177\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   author           5178 non-null   object \n",
      " 1   url              5178 non-null   object \n",
      " 2   date             5178 non-null   object \n",
      " 3   rating           5178 non-null   float64\n",
      " 4   review           5178 non-null   object \n",
      " 5   year             5178 non-null   int64  \n",
      " 6   review_length    5178 non-null   int64  \n",
      " 7   scores           5178 non-null   object \n",
      " 8   compound_scores  5178 non-null   float64\n",
      " 9   labels           5178 non-null   object \n",
      " 10  punct            5178 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 445.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df['punct'] = 0\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2a3e61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_23796\\1809218431.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['punct'][i] = df['punct'][i] + 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    doc = nlp(df['review'][i])\n",
    "    for word in doc:\n",
    "        if (word.pos_) == 'PUNCT':\n",
    "            df['punct'][i] = df['punct'][i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39ca3c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>year</th>\n",
       "      <th>review_length</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound_scores</th>\n",
       "      <th>labels</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paulclaassen</td>\n",
       "      <td>https://www.imdb.com/review/rw8032959/?ref_=tt...</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Over-complicated, way too long, and not all th...</td>\n",
       "      <td>2022</td>\n",
       "      <td>58</td>\n",
       "      <td>{'neg': 0.247, 'neu': 0.753, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neil</td>\n",
       "      <td>https://www.imdb.com/review/rw6050469/?ref_=tt...</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Far too clever for its own good</td>\n",
       "      <td>2020</td>\n",
       "      <td>31</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.459, 'pos': 0.541, 'comp...</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pedroborges</td>\n",
       "      <td>https://www.imdb.com/review/rw6217957/?ref_=tt...</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Tenet Review</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ThomDerd</td>\n",
       "      <td>https://www.imdb.com/review/rw6131705/?ref_=tt...</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>9.0</td>\n",
       "      <td>If you are into movies, Tenet is your jam.</td>\n",
       "      <td>2020</td>\n",
       "      <td>42</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dierregi</td>\n",
       "      <td>https://www.imdb.com/review/rw6051247/?ref_=tt...</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pretentious action movie</td>\n",
       "      <td>2020</td>\n",
       "      <td>24</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                                url  \\\n",
       "0  paulclaassen  https://www.imdb.com/review/rw8032959/?ref_=tt...   \n",
       "1          neil  https://www.imdb.com/review/rw6050469/?ref_=tt...   \n",
       "2   pedroborges  https://www.imdb.com/review/rw6217957/?ref_=tt...   \n",
       "3      ThomDerd  https://www.imdb.com/review/rw6131705/?ref_=tt...   \n",
       "4      dierregi  https://www.imdb.com/review/rw6051247/?ref_=tt...   \n",
       "\n",
       "         date  rating                                             review  \\\n",
       "0  2022-04-04     5.0  Over-complicated, way too long, and not all th...   \n",
       "1  2020-08-31     5.0                    Far too clever for its own good   \n",
       "2  2020-10-30     7.0                                       Tenet Review   \n",
       "3  2020-09-28     9.0         If you are into movies, Tenet is your jam.   \n",
       "4  2020-08-31     1.0                           Pretentious action movie   \n",
       "\n",
       "   year  review_length                                             scores  \\\n",
       "0  2022             58  {'neg': 0.247, 'neu': 0.753, 'pos': 0.0, 'comp...   \n",
       "1  2020             31  {'neg': 0.0, 'neu': 0.459, 'pos': 0.541, 'comp...   \n",
       "2  2020             12  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "3  2020             42  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "4  2020             24  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "\n",
       "   compound_scores    labels  punct  \n",
       "0          -0.3875  negative      4  \n",
       "1           0.7096  positive      0  \n",
       "2           0.0000   neutral      0  \n",
       "3           0.0000   neutral      2  \n",
       "4           0.0000   neutral      0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c46c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['review_length','punct']]\n",
    "y = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5324095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "467a976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694c83cb",
   "metadata": {},
   "source": [
    "### **LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74c81826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dadfff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34a31e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1609bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "689b4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf7ca48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg  neu  pos\n",
       "neg    0  314  133\n",
       "neu    0  476  133\n",
       "pos    0  320  178"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['neg','neu','pos'],columns=['neg','neu','pos'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03345a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       447\n",
      "     neutral       0.43      0.78      0.55       609\n",
      "    positive       0.40      0.36      0.38       498\n",
      "\n",
      "    accuracy                           0.42      1554\n",
      "   macro avg       0.28      0.38      0.31      1554\n",
      "weighted avg       0.30      0.42      0.34      1554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\dhruv-notes-datascience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\envs\\dhruv-notes-datascience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\envs\\dhruv-notes-datascience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad008d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42084942084942084"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3d96a",
   "metadata": {},
   "source": [
    "### **NAIVE BAYES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b351bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38e32b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train,y_train)\n",
    "predictions = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7e47bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>7</td>\n",
       "      <td>432</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>10</td>\n",
       "      <td>593</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>14</td>\n",
       "      <td>463</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg  neu  pos\n",
       "neg    7  432    8\n",
       "neu   10  593    6\n",
       "pos   14  463   21"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['neg','neu','pos'],columns=['neg','neu','pos'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70bad4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.23      0.02      0.03       447\n",
      "     neutral       0.40      0.97      0.57       609\n",
      "    positive       0.60      0.04      0.08       498\n",
      "\n",
      "    accuracy                           0.40      1554\n",
      "   macro avg       0.41      0.34      0.22      1554\n",
      "weighted avg       0.41      0.40      0.26      1554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6b127eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3996138996138996"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f3350a",
   "metadata": {},
   "source": [
    "### **SUPPORT VECTOR MECHANISM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ead8379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a2e0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(x_train,y_train)\n",
    "predictions = svc_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c5aaf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>0</td>\n",
       "      <td>498</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg  neu  pos\n",
       "neg    0  333  114\n",
       "neu    0  498  111\n",
       "pos    0  337  161"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['neg','neu','pos'],columns=['neg','neu','pos'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9eeb7898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       447\n",
      "     neutral       0.43      0.82      0.56       609\n",
      "    positive       0.42      0.32      0.36       498\n",
      "\n",
      "    accuracy                           0.42      1554\n",
      "   macro avg       0.28      0.38      0.31      1554\n",
      "weighted avg       0.30      0.42      0.34      1554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\dhruv-notes-datascience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\envs\\dhruv-notes-datascience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\envs\\dhruv-notes-datascience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6542ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4240669240669241"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea8530",
   "metadata": {},
   "source": [
    "## **TEXT ANALYTICS**\n",
    "### **TF-IDF Vectorizer and LINEAR Support Vector Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "211d79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['review']\n",
    "y = df['labels']\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4fd6fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3624,), (3624,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a3af7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1554,), (1554,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "892c06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60ce7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8076389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db0e279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d78daedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c17ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82b3734f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1569                                  Inconsistently dumb\n",
       "751               Terrible audio, vomit inducing visuals.\n",
       "3017          Nolan is changing the way we \"view\" movies.\n",
       "4223    A hollywood checklist of criteria combined wit...\n",
       "4001    Thank you, Mr Nolan, you are not making it eas...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8dfeac01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.74      0.78       447\n",
      "     neutral       0.81      0.89      0.84       609\n",
      "    positive       0.82      0.80      0.81       498\n",
      "\n",
      "    accuracy                           0.82      1554\n",
      "   macro avg       0.82      0.81      0.81      1554\n",
      "weighted avg       0.82      0.82      0.81      1554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c05c0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>331</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>35</td>\n",
       "      <td>539</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>37</td>\n",
       "      <td>64</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg  neu  pos\n",
       "neg  331   65   51\n",
       "neu   35  539   35\n",
       "pos   37   64  397"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['neg','neu','pos'],columns=['neg','neu','pos'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71e4116a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8153153153153153"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb1b62ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict(['Over-complicated, way too long, and not all that exciting.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b91bfe",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca2189",
   "metadata": {},
   "source": [
    "### **Accuracy**\n",
    "\n",
    "**Logistic Regression** = 0.424\n",
    "\n",
    "**Naive Bayes** = 0.39\n",
    "\n",
    "**Support Vector Classifier** = 0.424\n",
    "\n",
    "**Text Analytics = TF-IDF and Linear SVC** = 0.81"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shri-ganesh",
   "language": "python",
   "name": "dhruv-notes-datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
